In order to find the most suitable algorithm for translating a live input stream of American SLA to any other suitable SLA (sharing the same alphabet) in a real-world application, the algorithm needs to excel in two main aspects: accuracy and inference time. A third factor that may come into question here is the training time, as computational cost may accumulate when further improving the model in the future.

\subsection{Result from the long list}
As mentioned in chapter \ref{chapter_models} the long list contained 27 pretrained models. Due the the limited availability of computational ressources, the models on the list as per table \ref{tab:keras_models} (including all variants) were trainined in an experimental setup, to determine which models are suitable for a full training. The goal was to use these pretrained models and only train the last layer to enable the detection of SLA in sources such as webcam feeds, videos or images.

The experimental setup was trained on a consumer pc, with a 3.8 Ghz 6-core CPU, a \textit{GeForce GTX 1060} GPU and 32GB of RAM. The results mainly focus on two aspects in order to decide which models may be suitable for the full training: training time and accuracy. As shown in Fig. \ref{fig:long_list_acc} some of the models already have a high accuracy with a minified training.

\begin{figure}[h]
    \centering
    \caption{Accuracy on long list training}
	\label{fig:long_list_acc}
    \includegraphics[width=\linewidth]{figures/long_val_accuracy.png}
\end{figure}

While models as \textit{DenseNet} seem to have good results with all variants, others like \textit{ResNet} have a high variety, accuracy ranges from ~55\% (\textit{ResNet50}) to ~98\% \textit{ResNet50V2}. The \textit{EfficientNet} with all its variants has an accuracy below 10\% and will not move forward.

\begin{figure}[h]
    \centering
    \caption{Training time on long list training}
	\label{fig:long_list_time}
    \includegraphics[width=\linewidth]{figures/long_training_time.png}
\end{figure}

Fig. \ref{fig:long_list_time} shows the time that was needed to train the models with the reduced dataset for 10 epochs without early stopping. While it shows a wide range, the times generally speaking not too long at all. Therefore, the training time will not be the main factor for deciding which model we should move forward with.

When deploying the model in a real-time environment, such as a live detection via a webcam another factor comes into play: the inference time. As described in chapter \ref{chapter_models}, the models differ fundamentally in their architecture. At this point, it is uncertain how the architecural structure will affect the inference time of a fully trained model. Therefore we decided to move forward with the best performing model from each architecture described in chapters \ref{chapter_vgg16} to \ref{chapter_xception}. In addition to the top 5 models, we decided to add \textit{MobileNetV2} as well, as it seemed interesting why the newer version of the model did perform worse than the old one. Table \ref{tab:results:long} contains all models that will be used for a full training.

\begin{table}[th]
    \caption{Short List candidates}
    \label{tab:results:long}
    \centering
    \begin{tabular}{lll}
    \hline
    Name        & Acc.   & \begin{tabular}[c]{@{}l@{}}Time\\ (seconds)\end{tabular} \\ \hline
    MobileNet   & 0.9957 & 82                                                       \\
    MobileNetV2 & 0.9756 & 165                                                      \\
    DenseNet201 & 0.9842 & 328                                                      \\
    ResNet50V2  & 0.9239 & 178                                                      \\
    Xception    & 0.9698 & 238                                                      \\
    VGG16       & 0.9382 & 286                                                      \\ \hline
    \end{tabular}
\end{table}

\subsection{Result from the short list}

\subsection{Result from the prediction and translation}
