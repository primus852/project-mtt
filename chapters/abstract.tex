Every country has its own sign language. There is no universal sign language in the world to help deaf people communicate with others from other countries. This project focuses on developing a Sign Language Alphabet (SLA) translator that can play an important role by not only its interpretation but also helping deaf people to communicate with each other without learning a new sign language. In this project, the sign language used for training detective models is American sign language. The detective models were imported from pre-trained models for transfer learning in the Keras library. \textit{VGG16}, \textit{ResNet50V2}, \textit{MobileNet}, \textit{MobileNetV2}, \textit{DenseNet201}, and \textit{Xception} were selected as top performance models from each architecture by comparing the high accuracy performance with the partial learning for further processing training of the entire training dataset. After training the full training dataset, these six models were compared for accuracy, training duration, and inference time. The result showed that \textit{MobileNet} and \textit{MobileNetV2} have similar real-time capabilities: approx. 99\% of accuracy and approx. 0.03 seconds of inference time. In the end, the MobileNetV2 was successfully implemented with a test dataset to confirm the usability of translating to Turkish sign language images.

  Index terms should be included, as shown below.